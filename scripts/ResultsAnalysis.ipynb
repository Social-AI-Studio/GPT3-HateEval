{"cells":[{"cell_type":"code","source":["import csv\n","import time\n","import datetime\n","import math\n","import matplotlib.pyplot as plt\n","from collections import defaultdict"],"metadata":{"id":"Bt4inJhG6CIv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocess raw annotation data"],"metadata":{"id":"4r3T09LO6H0a"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"7tNgvDLH0kEm","executionInfo":{"status":"ok","timestamp":1684135017382,"user_tz":-480,"elapsed":2977,"user":{"displayName":"汪涵","userId":"01721555802280632406"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"faa738f2-1b2f-4d81-c76d-ba9b66c87beb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}],"source":["# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","\n","# root = \"gdrive/MyDrive/PlushProject/GPT3_explanation_evaluation/annotation/\"\n","root = \"../annotation\"\n","explanations_types = [\"hateful-WHY\", \"non-hateful-WHY\", \"both-WHY\" \"hateful-COT\", \"non-hateful-COT\", \"both-COT\" \"CONTEXT\", ]"]},{"cell_type":"code","source":["def takeFirst(elem):\n","    return int(elem[0])\n","def takeSecond(elem):\n","    return int(elem[1])\n","\n","# Assign labels to each tweet based on a majority voting on three annotations.\n","def label_based_on_score(hate_score_list):\n","  newElement = []\n","  temp = sorted(hate_score_list)\n","\n","  if(len(temp) >= 2):\n","    if(temp[-1] >= 4 and temp[-2] >= 4):\n","      newElement.append(\"hateful\")\n","      if(len(temp) == 2):\n","        newElement.append(\"consistent hateful\")\n","    elif(temp[0] <= 2 and temp[1] <= 2):\n","      newElement.append(\"non-hateful\")\n","      if(len(temp) == 2):\n","        newElement.append(\"consistent non-hateful\")\n","    else:\n","      newElement.append(\"neither\")\n","      if(len(temp) == 2 and temp[0] == 3 and  temp[1] == 3):\n","        newElement.append(\"consistent neither\")\n","      elif(len(temp) == 2):\n","        newElement.append(\"neither\")\n","      \n","    if(len(temp) == 3):\n","      if(temp[-1] >= 4 and temp[-2] >= 4):\n","        if(temp[0] >= 4):\n","          newElement.append(\"consistent hateful\")\n","        else:\n","          newElement.append(\"hateful\")\n","      elif(temp[0] <= 2 and temp[1] <= 2):\n","        if(temp[-1] <= 2):\n","          newElement.append(\"consistent non-hateful\")\n","        else:\n","          newElement.append(\"non-hateful\")\n","      elif(temp[0] == 3 and temp[1] == 3 and temp[-1] == 3):\n","          newElement.append(\"consistent neither\")\n","      else:\n","        newElement.append(\"neither\")\n","  else:\n","    if(temp[0] >= 4):\n","      newElement.append(\"hateful\")\n","      newElement.append(\"consistent hateful\")\n","    elif(temp[0] <= 2):\n","      newElement.append(\"non-hateful\")\n","      newElement.append(\"consistent non-hateful\")\n","    else:\n","      newElement.append(\"neither\")\n","      newElement.append(\"consistent neither\")\n","  return newElement\n","\n","# Perform preprocessing on the raw files by removing unnecessary columns. In cases where there are two explanations\n","# , average the two quality scores. Finally, annotate each tweet based on the majority voting from three annotators.\n","def processData(sourcePath, targetPath, clickWorker):\n","    title = [\"tweetId\", \"strategyId\", \"annotationId\", \"fluency\", \"informativeness\", \"persuasiveness\", \"soundness\", \\\n","             \"hatefulness\", \"hateLabel\", \"consistentHateLabel\"]\n","    leftList = []\n","    left = 0\n","    startIndex = 1 if clickWorker else 0\n","\n","    with open(sourcePath) as fs, open(targetPath, 'w', newline='') as tr:\n","        writer = csv.writer(tr)\n","        writer.writerow(title)\n","        \n","        reader = csv.reader(fs)\n","        next(reader)  # Skip header row\n","        data = list(reader)\n","        if(clickWorker == True):\n","          data.sort(key=takeSecond)\n","        else:\n","          data.sort(key=takeFirst)\n","\n","        for i in range(len(data)):\n","            start = max(i - 2, 0)\n","            end = min(i + 3, len(data))\n","            hatredList = []\n","            for j in range(start, end):\n","                if(data[j][startIndex + 0] == data[i][startIndex + 0]):\n","                  hatredList.append(int(data[j][-1]))\n","\n","            row = data[i]\n","            newElement = row[0 + startIndex : 3 + startIndex] \n","            qualityScore = [int(value) for value in row[-9:-1]]\n","            if(str(row[startIndex + 1]) == \"6\" or str(row[startIndex + 1]) == \"7\"):\n","              qualityScore = [sum(x) / 2.0 for x in zip(qualityScore[:4] , qualityScore[4:] )] \n","            else:\n","              qualityScore = qualityScore[:4]\n","\n","            newElement += qualityScore + [row[-1]] + label_based_on_score(hatredList)\n","            writer.writerow(newElement)\n","\n","            left += 1\n","            if((i * 3 + j + 1) % 75 == 0 or (i * 3 + j + 1) == len(data)):\n","              leftList.append(left)\n","              left = 0\n","    return leftList\n","\n"],"metadata":{"id":"3Xc0EoF2JqPC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["explanations_types = [\"No_EXP\",\"hateful-WHY\", \"non-hateful-WHY\", \"both-WHY\", \"hateful-COT\", \"non-hateful-COT\", \"both-COT\", \"both-COT_rm_unscroll\", \"CONTEXT\", ]\n","\n","for exp_typ in explanations_types:\n","  clickWorker = False\n","  if(exp_typ == \"non-hateful-WHY\"):\n","    clickWorker = True\n","  processData(root + exp_typ + \".csv\", root + exp_typ + \"_preprocessed.csv\", clickWorker)"],"metadata":{"id":"Vnww2RuRBAtr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate the quality table"],"metadata":{"id":"XyBk_Zb8CScy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6hA80_f1yMi"},"outputs":[],"source":["\n","def generateQualityTable(root, target_path):\n","    explanations_types = [\"hateful-WHY\", \"non-hateful-WHY\", \"both-WHY\", \"hateful-COT\", \"non-hateful-COT\", \"both-COT\", \"CONTEXT\", ]\n","    hatelabel = [\"non-hateful\", \"hateful\"]\n","    qualityLabel = [\"fluency\", \"informativeness\", \"persuasiveness\", \"soundness\" ]\n","    leftList = [0, 75, 75, 75, 75]\n","    strategyDic = {}\n","\n","    title = [\"\", \"Tweets Label\"]\n","    for exp_typ in explanations_types:\n","      title.append(exp_typ)\n","      strategyDic[exp_typ] = 0\n","\n","    with open(target_path, 'w') as file:\n","      writer = csv.writer(file)\n","      writer.writerow(title)\n","\n","      for qi in range(4):\n","        averageForQuality = 0\n","        for j in range(2):\n","          newElement = [qualityLabel[qi], hatelabel[j]]\n","          for exp_typ in explanations_types:\n","            with open(root + exp_typ + \"_preprocessed.csv\") as f:\n","              reader = csv.reader(f)\n","              next(reader)\n","              data = list(reader)\n","              tweetInterval = data[sum(leftList[:j * 2+1]):  sum(leftList[:j * 2 + 3])]\n","              qualityList = [float(tweet[3 + qi]) for tweet in tweetInterval]\n","              qualityScore = sum(qualityList)/ float(len(qualityList))\n","\n","              strategyDic[exp_typ] += qualityScore\n","              averageForQuality += qualityScore\n","\n","              newElement.append(round(qualityScore, 2))\n","          writer.writerow(newElement) \n","\n","generateQualityTable(root, root + \"evaluation_table/\" + \"qualityTable.csv\") "]},{"cell_type":"markdown","source":["# Generate the hatefulness table"],"metadata":{"id":"hFE3VdhsNHGV"}},{"cell_type":"code","source":["def generateHatefulnessTable(root, target_path):\n","    explanations_types = [\"No_EXP\", \"hateful-WHY\", \"non-hateful-WHY\", \"both-WHY\", \"hateful-COT\", \"non-hateful-COT\", \"both-COT\", \"CONTEXT\", ]\n","    hatelabel = [\"non-hateful\", \"hateful\"]\n","    baseline_value = {\"non-hateful\":0, \"hateful\":0}\n","    title = [\"hatefulness\"]\n","    for exp_typ in explanations_types:\n","      title.append(exp_typ)\n","\n","    with open(target_path, 'w') as file:\n","      writer = csv.writer(file)\n","      writer.writerow(title)\n","      for j in range(2):\n","        newElement = [hatelabel[j]]\n","        for exp_typ in explanations_types:\n","          path = root + exp_typ + \"_preprocessed.csv\"\n","                  \n","          with open(path) as f:\n","              reader = csv.reader(f)\n","              next(reader)\n","              data = list(reader)\n","              qualityList = [float(tweet[7]) for tweet in data[ j * 150 : (j + 1) * 150]]\n","\n","              qualityScore = sum(qualityList)/ float(len(qualityList))\n","\n","              if(exp_typ == \"No_EXP\"):\n","                baseline_value[hatelabel[j]] = qualityScore\n","                newElement.append(round(qualityScore, 2) )\n","              else:\n","                difference = qualityScore - baseline_value[hatelabel[j]]\n","                newElement.append(str(round(qualityScore, 2)) + \" (\" + str(round(difference, 2)) + \")\")\n","\n","        \n","        writer.writerow(newElement) \n","              \n","generateHatefulnessTable(root, root + \"evaluation_table/\" + \"hatefulnessTable.csv\") "],"metadata":{"id":"NOFoPP_8NKPm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Generate the misclassfied table"],"metadata":{"id":"kNwjyP8NMIvq"}},{"cell_type":"code","source":["hatelabel = [\"non-hateful\", \"hateful\", \"non-hateful\"]\n","\n","def getMisleadingTable(root, target_path):\n","    explanations_types = [\"hateful-WHY\", \"non-hateful-WHY\", \"both-WHY\", \"hateful-COT\", \"non-hateful-COT\", \"both-COT\", \"both-COT_rm_unscroll\" , \"CONTEXT\", ]\n","    title = [\"\", \"Transfer Type\"]\n","    for exp_typ in explanations_types:\n","      title.append(exp_typ)\n","\n","    with open(target_path, 'w') as file:\n","      writer = csv.writer(file)\n","      writer.writerow(title)\n","\n","      with open(root + \"No_EXP_preprocessed.csv\") as baseFile:\n","        reader = csv.reader(baseFile)\n","        next(reader)\n","        baseData = list(reader)\n","\n","        for qi in range(2):\n","              newElement = [\"Misclassified tweets\", hatelabel[qi] + \" as \" + hatelabel[qi+1]]\n","              for exp_typ in explanations_types:\n","                path = root + exp_typ + \"_preprocessed.csv\"\n","                \n","                with open(path) as baseFile:\n","                  reader = csv.reader(baseFile)\n","                  next(reader)\n","                  targetData = list(reader)\n","                  labelList = [\"-\" for i in range(100)]\n","                  i = 0\n","                  while i < len(targetData):\n","                    end = i+4\n","                    if(i + 4 >= len(targetData)):\n","                      end = len(targetData)\n","                    labelList[int(targetData[i][0]) - 1] = targetData[i][-2]\n","                    for j in range(i, end):\n","                      if(int(targetData[j][0]) != int(targetData[i][0])):\n","                        i = j\n","                        break\n","                      if(j == len(targetData) - 1):\n","                        i = len(targetData)\n","                        break\n","                  numOfTweets = int((len(baseData)) / 3.0)\n","\n","                  total = 0\n","                  for i in range(numOfTweets):\n","                    if(baseData[i * 3][-2] == hatelabel[qi] and labelList[i] == hatelabel[qi+1]):\n","                      total += 1\n","                  newElement.append(total)\n","\n","              writer.writerow(newElement) \n","getMisleadingTable(root, root + \"evaluation_table/\" + \"misclassifiedTable.csv\") \n"],"metadata":{"id":"5nspuY7cZsfX"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/kes76963/myproject/blob/main/gpt3_edit.ipynb","timestamp":1665576216973}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}